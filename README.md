# ETL-Analytics
search console ETL &amp; analytics

# ğŸš€ Node.js ETL Pipeline

A modular ETL pipeline built with Node.js that extracts data from Google APIs via OAuth 2.0, transforms it, and loads it using RabbitMQ (with optional ClickHouse support for analytics).

---

## 1ï¸âƒ£ Google OAuth Setup and `.env` Configuration

### ğŸ” Create OAuth Credentials:

1. Go to [Google Cloud Console](https://console.cloud.google.com/).
2. Create a project â†’ Navigate to **APIs & Services > Credentials**.
3. Click **â€œCreate Credentialsâ€ â†’ â€œOAuth client IDâ€**.
4. Choose **Desktop App** or **Web Application**.
5. Download `credentials.json`.

ğŸ“ Place `credentials.json` inside a `config/` folder in your project root.

### âš™ï¸ Create `.env` File:

```env
# Google OAuth
GOOGLE_CLIENT_ID=your-client-id
GOOGLE_CLIENT_SECRET=your-client-secret
GOOGLE_REDIRECT_URI=http://localhost:3000/oauth2callback

# RabbitMQ
RABBITMQ_URL=amqp://guest:guest@localhost:5672

# Optional: ClickHouse
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=9000
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=


Start RabbitMQ:
bash
Copy
Edit
docker run -d --hostname rabbit-host --name rabbitmq \
-p 5672:5672 -p 15672:15672 \
-e RABBITMQ_DEFAULT_USER=guest \
-e RABBITMQ_DEFAULT_PASS=guest \
rabbitmq:3-management

Run ETL Phases
ğŸ“¥ Extract Phase
bash
Copy
Edit
node extract/extract.js
Fetches data using Google OAuth 2.0

ğŸ§ª Transform Phase
bash
Copy
Edit
node transform/transform.js
Cleans and transforms extracted data

ğŸ“¤ Load Phase
bash
Copy
Edit
node load/load.js
Sends data to the destination (e.g., DB or ClickHouse)

ğŸ§µ Optional: Run RabbitMQ Worker
bash
Copy
Edit
node queue/worker.js
Listens to queue events and triggers ETL automatically

âœ… Install Dependencies
bash
Copy
Edit
npm install
ğŸ“¦ Tech Stack: Node.js, RabbitMQ, Google OAuth 2.0, dotenv, axios/fetch, optional ClickHouse
ğŸ§± Project Structure: Organized into extract/, transform/, load/, queue/, and config/

Your ETL pipeline is now ready to run and impress ğŸš€

